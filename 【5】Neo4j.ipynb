{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa90e9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T12:40:19.651598Z",
     "start_time": "2023-12-01T12:40:18.641225Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import jsonlines\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22034942",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:58:29.193088Z",
     "start_time": "2023-05-16T14:58:29.190091Z"
    }
   },
   "outputs": [],
   "source": [
    "filename=['中国图象图形学报','中文信息学报','模式识别与人工智能','计算机应用','计算机辅助设计与图形学学报']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e9a493e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:58:29.660512Z",
     "start_time": "2023-05-16T14:58:29.644786Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA=[]\n",
    "for f in filename:\n",
    "    with open(\"./DATA/\"+f+\".jsonl\",\"r+\",encoding=\"utf-8\") as ori:\n",
    "        for item in jsonlines.Reader(ori):\n",
    "            DATA.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e50769db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:58:30.124708Z",
     "start_time": "2023-05-16T14:58:30.116705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1501\n",
      "{'id': 32764, 'text': '3D多尺度深度卷积神经网络肺结节检测', 'label': [[5, 13, 'method'], [13, 18, 'RP'], [13, 18, 'rp']], 'Comments': []}\n",
      "[[5, 13, 'method'], [13, 18, 'RP'], [13, 18, 'rp']]\n"
     ]
    }
   ],
   "source": [
    "print(len(DATA))\n",
    "print(DATA[0])\n",
    "print(DATA[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44c4a12e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:58:30.602633Z",
     "start_time": "2023-05-16T14:58:30.590639Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(DATA)):\n",
    "    DATA[i]['id']=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "616fede8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:58:36.121129Z",
     "start_time": "2023-05-16T14:58:35.996132Z"
    }
   },
   "outputs": [],
   "source": [
    "method = pd.read_csv('./DATA/method.csv')\n",
    "method_dict={}\n",
    "for i in range(len(method)):\n",
    "    mi = method.iloc[i].dropna().values\n",
    "    for j in range(len(mi)):\n",
    "        method_dict.update({mi[j]:mi[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82baee73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab438dd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:58:38.981467Z",
     "start_time": "2023-05-16T14:58:38.900470Z"
    }
   },
   "outputs": [],
   "source": [
    "problems = pd.read_csv('./DATA/problems.csv')\n",
    "problems_dict={}\n",
    "for i in range(len(problems)):\n",
    "    pi = problems.iloc[i].dropna().values\n",
    "    for j in range(len(pi)):\n",
    "        problems_dict.update({pi[j]:pi[0]})      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "577a1382",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:59:50.244236Z",
     "start_time": "2023-05-16T14:59:50.224237Z"
    }
   },
   "outputs": [],
   "source": [
    "data_list=[]\n",
    "for i in range(len(DATA)):\n",
    "    num_m=[]\n",
    "    num_rp=[]\n",
    "    for j in range(len(DATA[i]['label'])):\n",
    "        if DATA[i]['label'][j][2]=='method':\n",
    "            try:\n",
    "                m_i_ = DATA[i]['text'][int(DATA[i]['label'][j][0]):int(DATA[i]['label'][j][1])]\n",
    "                m_i = method_dict[m_i_]\n",
    "                data_list.append([DATA[i]['id'],'paper','use','method',m_i])\n",
    "                num_m.append(m_i)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            \n",
    "        if DATA[i]['label'][j][2]=='rp':\n",
    "            try:\n",
    "                p_i_ = DATA[i]['text'][int(DATA[i]['label'][j][0]):int(DATA[i]['label'][j][1])]\n",
    "                p_i = problems_dict[p_i_]\n",
    "                data_list.append([DATA[i]['id'],'paper','focus','problems',p_i])\n",
    "                num_rp.append(p_i)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        for m in num_m:\n",
    "            for rp in num_rp:\n",
    "                data_list.append([rp,'problems','solve','method',m])\n",
    "                \n",
    "#                 data_list.append([m,'method','solve','problems',rp])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea04a231",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:59:52.389290Z",
     "start_time": "2023-05-16T14:59:52.382293Z"
    }
   },
   "outputs": [],
   "source": [
    "columns=['head_entity', 'head_type','relation','tail_type','tail_entity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd4b31ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:59:53.753367Z",
     "start_time": "2023-05-16T14:59:53.629388Z"
    }
   },
   "outputs": [],
   "source": [
    "connect = pd.read_csv('./connected.csv',index_col=0).reset_index(drop=True)\n",
    "for i in range(len(connect)):\n",
    "    connect.iloc[i][1] = connect.iloc[i][1].replace(\"['\",'').replace(\"']\",'')\n",
    "    data_list.append([connect.iloc[i][0],'problems','connect','ontology',connect.iloc[i][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4eea877d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:59:54.498986Z",
     "start_time": "2023-05-16T14:59:54.433962Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6261"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ontology = pd.read_csv('./Ont.csv',encoding=\"utf_8_sig\",index_col=0,header=1).reset_index(drop=True)\n",
    "for i in range(len(Ontology)):\n",
    "    data_list.append([Ontology.iloc[i][0],'ontology','hyponymy','ontology',Ontology.iloc[i][1]])\n",
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d469643e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:59:55.415187Z",
     "start_time": "2023-05-16T14:59:55.384271Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dict = dict(zip(columns,np.array(data_list).T))\n",
    "df_data = pd.DataFrame(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "730eff3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:59:56.809888Z",
     "start_time": "2023-05-16T14:59:56.784830Z"
    }
   },
   "outputs": [],
   "source": [
    "df_data.to_csv('./neo4j.csv',encoding=\"utf_8_sig\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855b2a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4839800c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T13:05:41.855454Z",
     "start_time": "2023-12-01T13:05:41.851304Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from py2neo import Node, Relationship, Graph, NodeMatcher, RelationshipMatcher,Subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "536ec16e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T13:22:24.078702Z",
     "start_time": "2023-12-01T13:22:24.060824Z"
    }
   },
   "outputs": [],
   "source": [
    "graph = Graph(\"http://localhost:7474/\", auth=(\"neo4j\", \"Emily525\"), name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b2bc95e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T12:56:13.057894Z",
     "start_time": "2023-12-01T12:56:13.051449Z"
    }
   },
   "outputs": [],
   "source": [
    "path = r\"./neo4j.csv\"\n",
    "file = open(path,'r',encoding = 'utf-8').readlines()\n",
    "\n",
    "con = list()\n",
    "zh = ['paper','method','problems','ontology','use','solve','focus','hyponymy','connect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d65c9b19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T12:56:13.997685Z",
     "start_time": "2023-12-01T12:56:13.984277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffhead_entity', 'head_type', 'relation', 'tail_type', 'tail_entity']\n"
     ]
    }
   ],
   "source": [
    "for j in file:\n",
    "    try:\n",
    "        a = j.replace(\"\\t\",\"\").strip('\\n').split(\",\")\n",
    "        # a = [eval(i) for i in a] #引号里面有引号-两对引号\n",
    "        a = [i for i in a] #只有一对引号\n",
    "        if (a[1] not in zh) or (a[2] not in zh) or (a[3] not in zh):\n",
    "            print(a)\n",
    "            continue\n",
    "        con.append(a)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c2df76a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T13:23:27.110402Z",
     "start_time": "2023-12-01T13:22:39.102794Z"
    }
   },
   "outputs": [],
   "source": [
    "for j in con_:\n",
    "    selector = NodeMatcher(graph) #创建图，实质上为句柄\n",
    "        # ---创建头实体节点---\n",
    "    entity1 = selector.match(j[1], name = j[0]) #检索是否存在头实体节点\n",
    "    if len(list(entity1)) == 0: #不存在头实体节点，则创建头实体\n",
    "        entity1_node = Node(j[1], name = j[0])\n",
    "        graph.create(entity1_node) #创建头实体\n",
    "    else: #存在头实体节点，跳过\n",
    "        pass\n",
    "\n",
    "        # ---创建尾实体节点---\n",
    "    entity3 = selector.match(j[3], name = j[4])\n",
    "    if len(list(entity3)) == 0: #不存在尾实体节点，则创建\n",
    "        \n",
    "        entity3_node = Node(j[3], name = j[4])\n",
    "        graph.create(entity3_node)   \n",
    "    else: #存在节点，跳过\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a9c88d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T13:24:15.494777Z",
     "start_time": "2023-12-01T13:23:39.066166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok1\n"
     ]
    }
   ],
   "source": [
    "for j in con_:\n",
    "        #将两虚点建立关系\n",
    "    e1_node = graph.nodes.match(j[1], name = j[0]).first()\n",
    "    e2_node = graph.nodes.match(j[3], name = j[4]).first()\n",
    "    e12 = Relationship(e1_node, j[2], e2_node)\n",
    "    graph.create(e12)\n",
    "\n",
    "print(\"ok1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
